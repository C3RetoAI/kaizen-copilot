{"collection_name": "astropy_astropy", "expected_file": "test_misc.py", "query": "    assert misc.dtype_bytes_or_chars(np.dtype(np.float64)) == 8\n        ([2], True),\ndef test_isiterable(obj, expectation):\n            '[2, \"Canopus\", -0.7300000190734863, \"F0Ib\"], '"}
{"collection_name": "astropy_astropy", "expected_file": "interval.py", "query": "class PercentileInterval(AsymmetricPercentileInterval):\n    Licensed under a 3-clause BSD style license (see AURA_LICENSE.rst).\n        vmax = np.max(values) if self.vmax is None else self.vmax\n__all__ = ["}
{"collection_name": "astropy_astropy", "expected_file": "test_separation.py", "query": "            0.69835342 * u.deg,\n        SeparationExpectation(\nfrom typing import NamedTuple\n            246.50823798 * u.deg,"}
{"collection_name": "astropy_astropy", "expected_file": "__init__.py", "query": "    \"BinTableHDU\",\nfrom .groups import Group, GroupData, GroupsHDU\nfrom .compressed import CompImageHDU\nfrom .hdulist import HDUList"}
{"collection_name": "astropy_astropy", "expected_file": "galactic.py", "query": "        The proper motion in Galactic longitude (including the ``cos(b)`` term)\nfrom .fk4 import FK4NoETerms\n        The proper motion in Galactic latitude for this object (``pm_l_cosb``\n    pm_b : `~astropy.units.Quantity` ['angular speed'], optional, keyword-only"}
{"collection_name": "astropy_astropy", "expected_file": "__init__.py", "query": "class and related tools to manage n-dimensional array-based data (e.g.\nfrom .nddata_withmixins import *\n[CLS] # Licensed under a 3-clause BSD style license - see LICENSE.rst\n        True,"}
{"collection_name": "astropy_astropy", "expected_file": "test_vo.py", "query": "    # See https://github.com/astropy/astroquery/pull/276\n        assert_array_equal(self.array[\"nulls\"], [0, -9, 2, -9, -9])\n        encoding=\"utf-8\",\n    )"}
{"collection_name": "astropy_astropy", "expected_file": "test_image_dask.py", "query": "    filename = tmp_path / \"test.fits\"\n    with fits.open(filename) as hdulist_new:\n    with fits.open(filename) as hdulist_new:\n        np.testing.assert_allclose(hdulist_new[0].data, dask_array_in_mem.compute())"}
{"collection_name": "astropy_astropy", "expected_file": "connect.py", "query": "    Get help on the available writers for ``Cosmology`` using the ``help()``\n# isort: split\n                    f\"{valid[0]} or its qualified name '{valid[1]}'\"\n        >>> cosmo1 = Cosmology.read('<file name>')"}
{"collection_name": "astropy_astropy", "expected_file": "__init__.py", "query": "__all__ = []\nfrom .merge import *\nfrom . import exceptions as _exceptions\nfrom .exceptions import *"}
{"collection_name": "django_django", "expected_file": "models.py", "query": "    headline = models.CharField(max_length=100)\n    alias = models.CharField(max_length=50, null=True, blank=True)\n    class Meta:\n    games = models.ManyToManyField(Game, related_name=\"players\")"}
{"collection_name": "django_django", "expected_file": "__init__.py", "query": "less disruptive .\nShared:\nkeeping them together made the implementation of Multiple Template Engines\n- django.template.loader_tags"}
{"collection_name": "django_django", "expected_file": "test_replace.py", "query": "            [\n                Concat(Value(\"Author: \"), F(\"name\")), Value(\"Author: \"), Value(\"\")\n            ],\n    def test_case_sensitive(self):"}
{"collection_name": "django_django", "expected_file": "0002_second.py", "query": "    operations = [\n    dependencies = [\n                    models.ForeignKey(\"migrations.Author\", models.SET_NULL, null=True),\n                    \"author\","}
{"collection_name": "django_django", "expected_file": "validation.py", "query": "        characters if they have a unique index on them.\n                )\n            errors.append(\n                    \"%s Strict Mode is not set for database connection '%s'\""}
{"collection_name": "django_django", "expected_file": "autoreload.py", "query": "            if self.check_server_status(ex):\n            expression = [\"name\", filenames]\n    @classmethod\n                # is the case."}
{"collection_name": "django_django", "expected_file": "0001_initial.py", "query": "[CLS] from django.conf import settings\n            [\n            [\n            ],"}
{"collection_name": "django_django", "expected_file": "raster.py", "query": "from functools import partial\n        c_double,\n        c_int,\n)"}
{"collection_name": "django_django", "expected_file": "fields.py", "query": "                    \"size\": 1,\nrun with a backend other than PostgreSQL.\n                }\n    )"}
{"collection_name": "django_django", "expected_file": "urls.py", "query": "    re_path(r\"^client/([0-9,]+)/$\", views.client, name=\"client\"),\n    re_path(r\"^Юникод/(?P<tag>\\S+)/$\", views.client2, name=\"метка_оператора_2\"),\n]\n    # Test urls for namespaces and current_app"}
{"collection_name": "matplotlib_matplotlib", "expected_file": "_tripcolor.py", "query": "    shading : {'flat', 'gouraud'}, default: 'flat'\n        kwargs['edgecolors'] = kwargs.pop('edgecolor')\n    if facecolors is not None:\n    c : array-like"}
{"collection_name": "matplotlib_matplotlib", "expected_file": "errorbar_limits_simple.py", "query": "#    plot-type: errorbar\nErrorbar limit selection\n#    - `matplotlib.axes.Axes.errorbar` / `matplotlib.pyplot.errorbar`\n# %%"}
{"collection_name": "matplotlib_matplotlib", "expected_file": "coords_report.py", "query": "\"\"\"\ndef millions(x):\nfig, ax = plt.subplots()\nplt.show()"}
{"collection_name": "matplotlib_matplotlib", "expected_file": "gridspec_multicolumn.py", "query": "        ax.text(0.5, 0.5, \"ax%d\" % (i+1), va=\"center\", ha=\"center\")\ndef format_axes(fig):\n=============================================\nax3 = fig.add_subplot(gs[1:, -1])"}
{"collection_name": "matplotlib_matplotlib", "expected_file": "customize_rc.py", "query": "plt.subplot(312)\n            \"font.weight\": \"bold\",  # bold fonts\n[CLS] \"\"\"\n    \"lines.linewidth\": 2,"}
{"collection_name": "matplotlib_matplotlib", "expected_file": "demo_parasite_axes.py", "query": "from mpl_toolkits.axisartist.parasite_axes import HostAxes\nThe standard and recommended approach is to use instead standard Matplotlib\npar2.set(ylim=(1, 65), ylabel=\"Velocity\")\n`mpl_toolkits.axes_grid1.parasite_axes.ParasiteAxes`."}
{"collection_name": "matplotlib_matplotlib", "expected_file": "usetex_baseline_test.py", "query": "    test_strings = [\"lg\", r\"$\\frac{1}{2}\\pi$\", r\"$p^{3^A}$\", r\"$p_{3_2}$\"]\n    ax.axvline(0, color=\"r\")\n        ax.text(0., 3 - i, s,\nimport matplotlib.pyplot as plt"}
{"collection_name": "matplotlib_matplotlib", "expected_file": "textpath.py", "query": "        xpositions = []\n        \"\"\"\n            codes.extend(codes1)\n        matplotlib.path.Path)."}
{"collection_name": "matplotlib_matplotlib", "expected_file": "fourier_demo_wx_sgskip.py", "query": "        panel = wx.Panel(self)\n        self.A.attach(self)\n        self.subplot2.set_ylabel(\"Time Domain Waveform x(t)\", fontsize=8)\n    \"\"\""}
{"collection_name": "matplotlib_matplotlib", "expected_file": "test_compare_images.py", "query": "        # Comparison with an image that is shifted by 1px in the X axis.\n    ])\n        # Now test with no tolerance.\n    results = compare_images("}
{"collection_name": "mwaskom_seaborn", "expected_file": "grouped_barplot.py", "query": "_thumb: .36, .5\ng.legend.set_title(\"\")\ng = sns.catplot(\n[CLS] \"\"\""}
{"collection_name": "mwaskom_seaborn", "expected_file": "test_plot.py", "query": "            y_shareset = getattr(root, \"get_shared_y_axes\")()\n        p = Plot(**xy).add(MockMark(), label=\"a\").add(MockMark(), label=\"b\").plot()\n        for i, key in enumerate(split_keys):\n        assert img.format == \"PNG\""}
{"collection_name": "mwaskom_seaborn", "expected_file": "version.py", "query": "            parts.append(f\".dev{self.dev}\")\n    Tuple[\n        if self.pre is not None:\n            )"}
{"collection_name": "mwaskom_seaborn", "expected_file": "test_aggregation.py", "query": "        assert_frame_equal(res1, res2)\n        return GroupBy(cols)\n        y = 1.5\n        ori = \"x\""}
{"collection_name": "mwaskom_seaborn", "expected_file": "histogram_stacked.py", "query": "import seaborn as sns\nsns.set_theme(style=\"ticks\")\nStacked histogram on a log scale\n    log_scale=True,"}
{"collection_name": "mwaskom_seaborn", "expected_file": "faceted_histogram.py", "query": ")\n    binwidth=3, height=3, facet_kws=dict(margin_titles=True),\nFacetting histograms by subsets of data\n_thumb: .33, .57"}
{"collection_name": "mwaskom_seaborn", "expected_file": "joint_histogram.py", "query": "# Load the planets dataset and initialize the figure\n# Add the joint and marginal histogram plots\ncax = g.figure.add_axes([.15, .55, .02, .2])\ng.plot_marginals(sns.histplot, element=\"step\", color=\"#03012d\")"}
{"collection_name": "mwaskom_seaborn", "expected_file": "test_distributions.py", "query": "        rugplot(x=values, ax=ax, expand_margins=False)\n        fill = ax2.collections[0]\n            dict(x=\"t\"),\n        lw = 2"}
{"collection_name": "mwaskom_seaborn", "expected_file": "_base.py", "query": "class VectorPlotter:\n            If True, yield an empty dataframe when no observations exist for\n        return self._comp_data\n                facet_vars & set(self.variables) - set(grouping_vars)"}
{"collection_name": "mwaskom_seaborn", "expected_file": "line.py", "query": "            lines = mpl.collections.LineCollection(**ax_data, **self.artist_kws)\nimport matplotlib as mpl\n    --------\n    Path : A mark connecting data points in the order they appear."}
{"collection_name": "pallets_flask", "expected_file": "helpers.py", "query": "        # namespace package. In this case pick the root path from the\n    \"\"\"Generate a URL to the given endpoint with the given values.\n    \"\"\"\ndef send_file("}
{"collection_name": "pallets_flask", "expected_file": "__init__.py", "query": "[CLS] from flask import Flask\napplication = Flask(__name__)"}
{"collection_name": "pallets_flask", "expected_file": "factory.py", "query": "def create_app():\n    return Flask(\"app\")\n    return Flask(\"_\".join([\"app2\", foo, bar]))\n[CLS] from flask import Flask"}
{"collection_name": "pallets_flask", "expected_file": "factory.py", "query": "def no_app():\n    return Flask(\"app\")\n[CLS] from flask import Flask\ndef create_app2(foo, bar):"}
{"collection_name": "pallets_flask", "expected_file": "sessions.py", "query": "    #: JSON derived serializer with support for some extra Python types\n        just returns the value of the ``SESSION_COOKIE_SECURE`` setting.\n        ``SameSite`` attribute. This currently just returns the value of\n                \"key_derivation\": self.key_derivation,"}
{"collection_name": "pallets_flask", "expected_file": "factory.py", "query": "    return Flask(\"app\")\n[CLS] from flask import Flask\ndef create_app():\ndef no_app():"}
{"collection_name": "pallets_flask", "expected_file": "wrappers.py", "query": "    default_mimetype: str | None = \"text/html\"\n    json_module = json\n    default.  Quite often you don't have to create this object yourself because\n    url_rule: Rule | None = None"}
{"collection_name": "pallets_flask", "expected_file": "conftest.py", "query": "@pytest.fixture(name=\"app\")\n    app.testing = False\n[CLS] import pytest\n@pytest.fixture"}
{"collection_name": "pallets_flask", "expected_file": "conftest.py", "query": "@pytest.fixture\n    app.testing = False\n[CLS] import pytest\n@pytest.fixture(name=\"app\")"}
{"collection_name": "pallets_flask", "expected_file": "tag.py", "query": "        \"\"\"Create a tagger for the given serializer.\"\"\"\n            if tag.check(value):\n        return [self.serializer.tag(item) for item in value]\n        return value.hex"}
{"collection_name": "psf_requests", "expected_file": "test_testserver.py", "query": "            sock = socket.socket()\n        \"\"\"multiple requests can be served\"\"\"\n        )\n        assert server.handler_results[0] == first_request"}
{"collection_name": "psf_requests", "expected_file": "adapters.py", "query": "        Returns a urllib3 connection for the given URL. This should not be\n    def get_connection(self, url, proxies=None):\n    port = parsed_request_url.port\n    LocationValueError,"}
{"collection_name": "psf_requests", "expected_file": "auth.py", "query": "        self.init_per_thread_state()\n        )\n            return r\n        base = ("}
{"collection_name": "psf_requests", "expected_file": "server.py", "query": "    def _handle_requests(self):\n                return None\n                break\n        )"}
{"collection_name": "psf_requests", "expected_file": "utils.py", "query": "        scheme = new_scheme\n    \"\"\"\n    To create a header from the :class:`dict` again, use the\n    return result"}
{"collection_name": "psf_requests", "expected_file": "flask_theme_support.py", "query": "     Number, Operator, Generic, Whitespace, Punctuation, Other, Literal\n        Generic:                   \"#000000\",        # class: 'g'\n        Punctuation:               \"bold #000000\",   # class: 'p'\n        String.Double:             \"#4e9a06\",        # class: 's2'"}
{"collection_name": "psf_requests", "expected_file": "certs.py", "query": "This module returns the preferred default CA certificate bundle. There is\npackaged CA bundle.\nfrom certifi import where\nenvironment, you can change the definition of where() to return a separately"}
{"collection_name": "psf_requests", "expected_file": "test_help.py", "query": "    \"\"\"\n    \"\"\"Older versions of IDNA don't provide a __version__ attribute, verify\n    def __init__(self, version):\n    \"\"\"Verify we're actually setting system_ssl when it should be available.\"\"\""}
{"collection_name": "psf_requests", "expected_file": "test_help.py", "query": "[CLS] from unittest import mock\ndef test_idna_without_version_attribute():\n        assert info()[\"idna\"] == {\"version\": \"2.6\"}\n    \"\"\""}
{"collection_name": "psf_requests", "expected_file": "test_testserver.py", "query": "            assert r.headers[\"Content-Length\"] == \"6\"\n        server = Server.basic_response_server(requests_to_handle=2)\n        first_request = b\"put your hands up in the air\"\n[CLS] import socket"}
{"collection_name": "pydata_xarray", "expected_file": "test_ufuncs.py", "query": "        xr.Variable([\"x\"], [1, 1]),\n        assert isinstance(actual, float)\n    @requires_dask\n    def test_ufunc_duck_array_dataarray(self):"}
{"collection_name": "pydata_xarray", "expected_file": "cftimeindex.py", "query": "            ):\n# The pandas.Index subclass defined here was copied and adapted for\n        result._cache = {}\n            return pd.DatetimeIndex([])"}
{"collection_name": "pydata_xarray", "expected_file": "facetgrid.py", "query": "        if \"label\" not in kwargs:\n        >>> ds = xr.tutorial.scatter_example_dataset(seed=42)\n        self: T_FacetGrid,\n        \"\"\""}
{"collection_name": "pydata_xarray", "expected_file": "test_plot.py", "query": "        Check if the outer vertices of the pcolormesh are the expected values\n        assert axes is not None\n        assert cmap_params[\"vmin\"] == np.percentile(self.data, 2)\n            assert image.norm is norm"}
{"collection_name": "pydata_xarray", "expected_file": "reindexing.py", "query": "        ).load()\n            x=np.arange(0, nx, 0.5), y=np.arange(0, ny, 0.5), method=\"nearest\"\nny = 50\n        requires_dask()"}
{"collection_name": "pydata_xarray", "expected_file": "test_indexing.py", "query": ")\n    ds = Dataset(\n    assert_array_equal,\n    )"}
{"collection_name": "pydata_xarray", "expected_file": "fit.py", "query": "            if full:  # Copy np.polyfit behavior\n                unexpected = set(bound.dims) - set(preserved_dims)\n        Default is True if data is stored in a dask.array or if there is any\n                lb + 1,  # lower bound finite, upper infinite"}
{"collection_name": "pydata_xarray", "expected_file": "test_parallelcompat.py", "query": "from xarray.namedarray.daskmanager import DaskManager\n        self.chunks = getattr(obj, \"chunks\", None)\n    KNOWN_CHUNKMANAGERS,\n            assert isinstance(chunkmanager, DummyChunkManager)"}
{"collection_name": "pydata_xarray", "expected_file": "dtypes.py", "query": "    Returns\n    -------\n        # See https://github.com/numpy/numpy/issues/10685\n    *arrays_and_dtypes : list of arrays and dtypes"}
{"collection_name": "pydata_xarray", "expected_file": "facetgrid.py", "query": "            # The column titles on the top row\n        Parameters\n                func,\n            )"}
{"collection_name": "pylint-dev_pylint", "expected_file": "kwarg_superseded_by_positional_arg.py", "query": "def name2(apple=\"Green apple\", /, **kwargs):\n    {'apple': 'Red apple'}\n    print(apple)\n    Red apple"}
{"collection_name": "pylint-dev_pylint", "expected_file": "good.py", "query": "    :param b: second integer\n    return a + b\n[CLS] def integer_sum(a: int, b: int):\n    :param a: first integer"}
{"collection_name": "pylint-dev_pylint", "expected_file": "bad.py", "query": "[CLS] def important_string_manipulation(x: str, y: str) -> None:\n    if y != \"\":  # [use-implicit-booleaness-not-comparison-to-string]\n    if x == \"\":  # [use-implicit-booleaness-not-comparison-to-string]\n        print(\"x is an empty string\")"}
{"collection_name": "pylint-dev_pylint", "expected_file": "__init__.py", "query": "raise missing.Missing..\n[CLS] import missing"}
{"collection_name": "pylint-dev_pylint", "expected_file": "missing_raises_doc.py", "query": "# pylint: disable=unused-argument, import-error, unused-variable, no-member, try-except-raise\n[CLS] \"\"\"Tests for missing-raises-doc and missing-raises-type-doc\"\"\"\ndef test_no_crash_when_inferring_handlers():\ndef test_ignores_unknown_style(self):"}
{"collection_name": "pylint-dev_pylint", "expected_file": "typealias_naming_style_default.py", "query": "TBadName: TypeAlias = int  # [invalid-name]\nGood2Name: TypeAlias = int\n    local_bad_name: TypeAlias = int  # [invalid-name]\n    del LocalGoodName, local_bad_name, LocalTypeAliasToUnion"}
{"collection_name": "pylint-dev_pylint", "expected_file": "good.py", "query": "[CLS] FRUITS = {\"apple\": 1, \"pear\": 5, \"peach\": 10}\n    print(fruit)\nfor fruit in FRUITS:"}
{"collection_name": "pylint-dev_pylint", "expected_file": "third.py", "query": "    xxxx = 1\n[CLS] r\"\"\"A raw docstring.\n    wwww = 4\n\"\"\""}
{"collection_name": "pylint-dev_pylint", "expected_file": "bad.py", "query": "    def __init__(self):\n    except ZeroDivisionError as e:\n    try:\ndef calculate_speed(distance: float, time: float) -> float:"}
{"collection_name": "pylint-dev_pylint", "expected_file": "first_arg.py", "query": "    # C0202, classmethod\n        pass\n    def class2(other):  # [bad-mcs-classmethod-argument]\n        pass"}
{"collection_name": "pytest-dev_pytest", "expected_file": "test_reporting.py", "query": "        @pytest.fixture\n    result = pytester.runpytest()\n    \"\"\"\n    \"\"\""}
{"collection_name": "pytest-dev_pytest", "expected_file": "test_foo.py", "query": "[CLS] # mypy: allow-untyped-defs\nfrom __future__ import annotations\ndef test_foo():\n    pass"}
{"collection_name": "pytest-dev_pytest", "expected_file": "truncate.py", "query": "    # 64 (for the base message:\n    # Create truncated explanation with modified final line\n    return explanation\n    truncated_line_count = len(input_lines) - len(truncated_explanation)"}
{"collection_name": "pytest-dev_pytest", "expected_file": "tox_run.py", "query": "from __future__ import annotations\n\"\"\"\n[CLS] \"\"\"\nif __name__ == \"__main__\":"}
{"collection_name": "pytest-dev_pytest", "expected_file": "timing.py", "query": "import dataclasses\n    time: float = dataclasses.field(default_factory=lambda: time(), init=False)\n        \"\"\"Instant as UTC datetime.\"\"\"\n    stop: Instant"}
{"collection_name": "pytest-dev_pytest", "expected_file": "collect.py", "query": "    '''\n        result = pytester.runpytest()\n                    return MyFunction.from_parent(name=name, parent=collector)\n                        return self._func.__get__(inst, owner)()"}
{"collection_name": "pytest-dev_pytest", "expected_file": "terminal.py", "query": "                \"\\\\\", nodes.SEP\n                markup = {\"green\": True}\n            char = char.lower()\n        action=\"store_false\","}
{"collection_name": "pytest-dev_pytest", "expected_file": "conftest.py", "query": "from __future__ import annotations\n@pytest.fixture\ndef arg1(request):\n        request.getfixturevalue(\"arg2\")"}
{"collection_name": "pytest-dev_pytest", "expected_file": "manyparam.py", "query": "def foo(request):\ndef test_it2(foo):\ndef test_it(foo):\n    return request.param"}
{"collection_name": "pytest-dev_pytest", "expected_file": "test_compare_initvar.py", "query": "def test_demonstrate():\nclass Foo:\n@dataclass\n[CLS] # mypy: allow-untyped-defs"}
{"collection_name": "scikit-learn_scikit-learn", "expected_file": "check_xfailed_checks.py", "query": "    failed_test_names = set(e[\"check_name\"] for e in failed_tests)\nfrom sklearn.utils.estimator_checks import check_estimator\nfrom sklearn.utils._test_common.instance_generator import (\n    expected_but_not_raised = expected_failed_tests - failed_test_names"}
{"collection_name": "scikit-learn_scikit-learn", "expected_file": "_plot.py", "query": "            `None`, we use `\"Score\"` if `negate_score` is `False` and `\"Negative score\"`\n    >>> tree = DecisionTreeClassifier(random_state=0)\n                        x_data,\n            computing the score are parallelized over the different training"}
{"collection_name": "scikit-learn_scikit-learn", "expected_file": "test_mocking.py", "query": "    getattr(clf, pred_func)(X)\n    y_decision = clf.decision_function(X)\ndef test_check_on_fit_success(iris, kwargs):\n    X, y = iris"}
{"collection_name": "scikit-learn_scikit-learn", "expected_file": "plot_roc.py", "query": "# Plot all OvR ROC curves together\n        name=f\"{label_b} as positive class\",\nof TPR or FPR is obtained only after binarizing the output. This can be done in\n        b_true,"}
{"collection_name": "scikit-learn_scikit-learn", "expected_file": "plot_bisect_kmeans.py", "query": "[CLS] \"\"\"\nX, _ = make_blobs(n_samples=n_samples, centers=2, random_state=random_state)\n# Make subplots for each variant\n\"\"\""}
{"collection_name": "scikit-learn_scikit-learn", "expected_file": "_laplacian.py", "query": "        if m.format == \"dia\":\n        dtype = m.dtype\n    for a noisy directed linear graph.\n        else:"}
{"collection_name": "scikit-learn_scikit-learn", "expected_file": "_config.py", "query": "    \"print_changed_only\": True,\n    return _threadlocal.global_config\n        array_api_dispatch=array_api_dispatch,\n    set_config : Set global scikit-learn configuration."}
{"collection_name": "scikit-learn_scikit-learn", "expected_file": "plot_calibration_multiclass.py", "query": "# simplex. This same renormalization step is performed internally by the\n)\n# Use the three class-wise calibrators to compute calibrated probabilities\n    )"}
{"collection_name": "scikit-learn_scikit-learn", "expected_file": "utils.py", "query": "    caller.test_scorer = lambda _, __: (\n[CLS] import numpy as np\ndef make_gen_reg_scorers(caller):\n    caller.test_scorer = balanced_accuracy_score"}
{"collection_name": "scikit-learn_scikit-learn", "expected_file": "__init__.py", "query": "[CLS] # Authors: The scikit-learn developers\n# SPDX-License-Identifier: BSD-3-Clause"}
{"collection_name": "sphinx-doc_sphinx", "expected_file": "foo.py", "query": "[CLS] MESSAGE = \"There's no __init__.py in this folder, hence we should be left out\""}
{"collection_name": "sphinx-doc_sphinx", "expected_file": "parallel.py", "query": "        precv, psend = multiprocessing.Pipe(False)\n        self._procs: dict[int, Any] = {}\n[CLS] \"\"\"Parallel building utilities.\"\"\"\nexcept ImportError:"}
{"collection_name": "sphinx-doc_sphinx", "expected_file": "index_entries.py", "query": "            return _split_into(2, 'single', value)\n    # new entry types must be listed in util/nodes.py!\n    if len(list(filter(None, parts))) < n:\n    if entry_type in {'see', 'seealso'}:"}
{"collection_name": "sphinx-doc_sphinx", "expected_file": "source_parser.py", "query": "class TestSourceParser(Parser):\n    app.add_source_suffix('.test', 'test')\n    app.add_source_parser(TestSourceParser)\n    supported = ('test',)"}
{"collection_name": "sphinx-doc_sphinx", "expected_file": "test_smartquotes.py", "query": "    confoverrides={'language': 'ja'},\n    testroot='smartquotes',\n    assert '\\\\textendash{} “Sphinx” is a tool that makes it easy …' in content\n    'html',"}
{"collection_name": "sphinx-doc_sphinx", "expected_file": "__init__.py", "query": "[CLS] \"\"\"Contains Sphinx features not activated by default.\"\"\""}
{"collection_name": "sphinx-doc_sphinx", "expected_file": "roles.py", "query": "    def process_link(\n        )\n            reference = nodes.reference(\n            self.nodeclass = nodeclass"}
{"collection_name": "sphinx-doc_sphinx", "expected_file": "test_environment_record_dependencies.py", "query": "    assert app.env.dependencies['api'] == {_StrPath('example_module.py')}\n[CLS] \"\"\"Tests for ``record_dependencies``.\"\"\"\nif TYPE_CHECKING:\nfrom __future__ import annotations"}
{"collection_name": "sphinx-doc_sphinx", "expected_file": "test_ext_autodoc_autofunction.py", "query": "    ]\n        '.. py:function:: coroutinefunc()',\n    assert list(actual) == [\n        '',"}
{"collection_name": "sphinx-doc_sphinx", "expected_file": "test_build_html_copyright.py", "query": "    from sphinx.testing.util import SphinxTestApp\n    assert '  &#169; Copyright 2010-2013, Bob.<br/>\\n' in content\n        '    \\n'\n        yield time.gmtime(source_date_epoch).tm_year"}
{"collection_name": "sympy_sympy", "expected_file": "test_sequences.py", "query": "    assert isinstance(SeqMul(per, per_bou, evaluate=False), SeqMul)\n    assert per + (SeqPer((2, 3))) == SeqPer((3, 5), (n, 0, oo))\n    assert SeqFormula(r, (i, 0, 5))[:] == [r.subs(i, j) for j in range(6)]\n    assert s.periodical == Tuple(1, n, 3)"}
{"collection_name": "sympy_sympy", "expected_file": "rl.py", "query": "    \"\"\"\n                       *[arg for arg, x in zip(expr.args, ids) if not x])\n        if set(newargs) != set(expr.args):\n    Basic(1, 2)"}
{"collection_name": "sympy_sympy", "expected_file": "subscheck.py", "query": "    1. Substitute the solution for `f` in the original equation.  This only\n    can be supplied through the ``func`` argument.\n                        lhs = ode_or_bool.lhs\n    This works when ``func`` is one function, like `f(x)` or a list of"}
{"collection_name": "sympy_sympy", "expected_file": "frv_types.py", "query": "    ========\n    RandomSymbol\n                distribution having different weights for each\n    References"}
{"collection_name": "sympy_sympy", "expected_file": "limits.py", "query": "                else:\n    ========\n                except PolynomialError:\n                    if sig.is_zero:"}
{"collection_name": "sympy_sympy", "expected_file": "polyerrors.py", "query": "    \"\"\"Raised if ``roots`` is called with strict=True and a polynomial\nclass PolificationFailed(PolynomialError):\n            return \"%s does not divide %s\" % (sstr(self.g), sstr(self.f))\n        if not self.seq:"}
{"collection_name": "sympy_sympy", "expected_file": "test_hadamard.py", "query": "Z = MatrixSymbol('Z', n, n)\nfrom sympy.testing.pytest import raises, warns_deprecated_sympy\n    raises(ShapeError, lambda: HadamardPower(A, B))\n    raises(ValueError, lambda: HadamardProduct())"}
{"collection_name": "sympy_sympy", "expected_file": "_parse_latex_antlr.py", "query": "def convert_ceil(ceil):\n                  and frac.upper.start.type == LaTeXLexer.SYMBOL\n    if func.supexpr().expr():  # ^{expr}\ndef handle_integral(func):"}
{"collection_name": "sympy_sympy", "expected_file": "group_numbers.py", "query": "    \"\"\"\n                  (3*p + 31)*gcd(p-1, 5) + 4*gcd(p-1, 7) + 5*gcd(p-1, 8) + gcd(p-1, 9)\n    Since `n` is assumed to be squarefree, the divisor `d` of `n` can be identified with the power set of prime factors.\n    Note that ``factors`` is a prime factorization of `n`."}
{"collection_name": "sympy_sympy", "expected_file": "test_applyfunc.py", "query": "    assert expr[0, 0] == double(Xd[0, 0])\nfrom sympy.core.function import Lambda\n        [sin(X[0, 0]), sin(X[0, 1]), sin(X[0, 2])],\nfrom sympy.matrices.expressions.matexpr import MatrixSymbol"}
